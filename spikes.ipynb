{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "- spikes are given as input instead of rr interval values\n",
    "\n",
    "### Time taken to run ANN(approx)\n",
    "\n",
    "| Length of input array | Time taken to run |\n",
    "| --------------------- | ----------------- |\n",
    "| 10_000_000            | 19 min            |\n",
    "| 1_000_000             | 1 min 15 sec      |\n",
    "| 100_000               | 10 sec            |\n",
    "| 3600                  | 0.2 sec           |\n",
    "\n",
    "### Time taken to run SNN(approx, excluding ANN)\n",
    "\n",
    "| Length of input array | Time taken to run |\n",
    "| --------------------- | ----------------- |\n",
    "| 10_000_000            | todo              |\n",
    "| 1_000_000             | 30 min            |\n",
    "| 100_000               | 3 min 30 sec      |\n",
    "| 3600                  | 6 sec             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring new class IF_Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate and Fire Neuron Object\n",
    "\n",
    "\n",
    "class IF_Neuron:\n",
    "    def __init__(self, layer, weights, bias, steps, v_th):\n",
    "        self.layer = layer  # Layer of Neuron\n",
    "        self.weights = weights  # Weights\n",
    "        self.bias = bias  # Bias\n",
    "\n",
    "        # IF Properties\n",
    "        self.steps = steps  # Number of steps for calculation\n",
    "        self.v = np.empty([self.steps])  # Neuron Value\n",
    "        self.v[0] = 0  # Set start Value\n",
    "        self.spikes = np.empty([self.steps])  # Output spike train\n",
    "        self.n_spikes = 0  # Number of spikes\n",
    "        self.v_th = v_th  # Threshold\n",
    "\n",
    "    def reset(self):  # Reset Neuron\n",
    "        self.v = np.empty([self.steps])\n",
    "        self.v[0] = 0\n",
    "        self.spikes = np.empty([self.steps])\n",
    "        self.n_spikes = 0\n",
    "\n",
    "    def calculate(self, neuron_input):\n",
    "        for i in range(self.steps):  # for every step\n",
    "            if i > 0:  # not first element\n",
    "                self.v[i] = self.v[i - 1]\n",
    "            for j in range(len(neuron_input)):  # for every input channel\n",
    "                if neuron_input[j][i]:  # if spike present\n",
    "                    self.v[i] = self.v[i] + self.weights[j]\n",
    "            self.v[i] = self.v[i] + self.bias\n",
    "            if self.v[i] > self.v_th:  # if above threshold\n",
    "                self.n_spikes += 1  # increase number of spikes\n",
    "                self.spikes[i] = 1  # add spike to spike trace\n",
    "                self.v[i] = self.v[i] - self.v_th  # difference reset\n",
    "                # self.Vm[i] = self.bias            # hard reset\n",
    "            else:  # add no spike to spike trace\n",
    "                self.spikes[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron model for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuron Object for ANN\n",
    "class Neuron:\n",
    "    def __init__(self, layer, weights, bias):\n",
    "        self.layer = layer  # layer\n",
    "        self.weights = weights  # weights\n",
    "        self.bias = bias  # bias\n",
    "        self.output = 0  # output\n",
    "\n",
    "    def calculate(self, inputs):  # calculation\n",
    "        relu_activation = ReLU()\n",
    "        x = np.dot(self.weights, inputs) + self.bias\n",
    "        self.output = relu_activation.calculate(x)\n",
    "\n",
    "\n",
    "# ReLU activation function\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.output = 0\n",
    "\n",
    "    def calculate(self, x):\n",
    "        self.output = np.maximum(0, x)  # relu function\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `load_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network structure, weights, biases and activation of output neurons of existing ANN\n",
    "def load_model():\n",
    "    network_structure = [2, 8, 7]  # input layer, hidden layer, output layer\n",
    "    weights = np.array(\n",
    "        [\n",
    "            [3.8722e00, -1.9211e-01],\n",
    "            [5.3290e00, 4.7047e-01],\n",
    "            [-5.1274e00, -5.1903e-03],\n",
    "            [-2.1598e-01, 3.8066e00],\n",
    "            [8.6600e-02, -8.0032e00],\n",
    "            [5.6373e00, -1.5221e-01],\n",
    "            [1.2375e00, 4.9385e-01],\n",
    "            [3.5665e00, 3.5465e-01],\n",
    "            [1.4272, -6.1945, -2.0182, 1.3436, 2.2910, 0.4987, 0.3354, -3.3586],\n",
    "            [-1.1558, -0.3980, -3.7244, -1.4081, -2.3210, -1.6481, -2.1048, -0.4278],\n",
    "            [-8.2870, -1.0868, 0.8291, 0.7862, -21.4690, -17.1373, -0.5934, -0.1413],\n",
    "            [-4.1481, -0.5656, 2.4139, -9.3905, -2.0829, -16.9980, -0.0992, -0.9269],\n",
    "            [0.5731, 1.5926, -18.0025, -0.3991, -16.3425, 0.7215, 0.3035, 1.3948],\n",
    "            [0.8768, 0.5940, -13.4116, -7.6260, 0.3059, 1.4851, 0.7284, 0.3347],\n",
    "            [-7.8029, -0.9323, 0.8822, -36.0286, 3.4898, -18.0212, -3.9245, -0.6883],\n",
    "        ],\n",
    "        dtype=object,\n",
    "    )\n",
    "    biases = np.array(\n",
    "        [\n",
    "            3.1150,\n",
    "            -1.4917,\n",
    "            2.9950,\n",
    "            2.6293,\n",
    "            -2.0631,\n",
    "            3.2291,\n",
    "            1.8875,\n",
    "            -1.5298,\n",
    "            0.7810,\n",
    "            -1.4082,\n",
    "            -1.0581,\n",
    "            1.9883,\n",
    "            -1.8215,\n",
    "            0.3030,\n",
    "            -1.5795,\n",
    "        ],\n",
    "    )\n",
    "    classification_threshold = 0.5  # output activation needed to assign to class\n",
    "\n",
    "    return network_structure, weights, biases, classification_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_neurons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neurons(structure, weights, biases, steps, v_th, net_type):\n",
    "    neuron_array = []  # array in which the neuron objects will be saved\n",
    "    neuron_number = 0  # counter to initialize/create the neuron objects\n",
    "\n",
    "    for layer in range(\n",
    "        1, len(structure)\n",
    "    ):  # for every layer (except layer 0 which is input)\n",
    "        for neuron in range(structure[layer]):  # for number of neurons in layer\n",
    "            if net_type == \"SNN\":  # create SNN neurons\n",
    "                neuron_array.append(\n",
    "                    IF_Neuron(\n",
    "                        layer,\n",
    "                        weights[neuron_number],\n",
    "                        biases[neuron_number],\n",
    "                        steps,\n",
    "                        v_th[layer - 1],\n",
    "                    )\n",
    "                )\n",
    "            else:  # create ANN neurons\n",
    "                neuron_array.append(\n",
    "                    Neuron(layer, weights[neuron_number], biases[neuron_number])\n",
    "                )\n",
    "            neuron_number += 1\n",
    "\n",
    "    return neuron_array  # array of neuron objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `reset_neurons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_neurons(neuron_array):\n",
    "    for neuron in neuron_array:\n",
    "        neuron.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_input_spike`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_spike(input_array, steps):\n",
    "    input_spike = np.zeros(steps)\n",
    "    # rr_values_array=rr_values_array.astype(int)\n",
    "    # for i, value in enumerate(rr_values_array):\n",
    "    for l in range(steps):\n",
    "        rnd = random.randrange(60, 120)\n",
    "        # print(f\"rnd:{rnd}\")\n",
    "        # print(f\"input_array:{rr_values_array}\")\n",
    "        print(f\"input_spike:{input_spike}\")\n",
    "        if rnd < input_array:\n",
    "            input_spike[l] = 1\n",
    "\n",
    "    return input_spike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_input_spikes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_spikes(input_array, steps):\n",
    "    input_spikes = np.zeros(shape=(2, steps))\n",
    "    for i, interval in enumerate(input_array):  \n",
    "        for step in range(steps):  \n",
    "            rnd = random.randrange(0, 2)\n",
    "            if rnd < interval:  # create spikes\n",
    "                input_spikes[i][step] = 1\n",
    "\n",
    "    return input_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `calculate_pixel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixel(network_structure, neuron_array, input_elements, net_type):\n",
    "    max_activation = [0] * len(network_structure)\n",
    "    for layer in range(1, len(network_structure)):  # for layer\n",
    "        if layer == 1:  # if input layer\n",
    "            neuron_input_array = input_elements  # get img values as input\n",
    "        else:  # otherwise, get outputs of previous layer\n",
    "            neuron_input_array = []\n",
    "            for neuron in neuron_array:\n",
    "                if neuron.layer == layer - 1:\n",
    "                    if net_type == \"SNN\":\n",
    "                        neuron_input_array.append(neuron.spikes)  # spikes output\n",
    "                    else:\n",
    "                        neuron_input_array.append(neuron.output)\n",
    "        for neuron in neuron_array:  # get all neurons of current layer and calculate\n",
    "            if neuron.layer == layer:\n",
    "                if net_type == \"SNN\":\n",
    "                    neuron.calculate(neuron_input_array)\n",
    "                else:\n",
    "                    neuron.calculate(neuron_input_array)\n",
    "                    max_activation[layer] = max(max_activation[layer], neuron.output)\n",
    "    return max_activation  # max activation per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `calculate_network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_network(network_structure, neuron_array, input_array, steps, net_type):\n",
    "    output_array = []\n",
    "    max_activation = [0] * len(network_structure)\n",
    "    max_activation[0] = 1\n",
    "    number_of_total_spikes = 0\n",
    "\n",
    "    for i, pixel in enumerate(input_array):  # for every pixel\n",
    "        if (i + 1) / len(input_array) * 100 % 1 == 0:  # print status update\n",
    "            print(\"\\r\", f\"{int((i+1)/len(input_array)*100)}% done\", end=\"\")\n",
    "        if net_type == \"SNN\":  # if SNN\n",
    "            reset_neurons(neuron_array)  # reset neurons\n",
    "            input_spikes = create_input_spikes(pixel, steps)  # convert input to spikes\n",
    "            calculate_pixel(network_structure, neuron_array, input_spikes, net_type)\n",
    "        else:  # if ANN\n",
    "            temp_max_act = calculate_pixel(\n",
    "                network_structure, neuron_array, pixel, net_type\n",
    "            )\n",
    "            for j, element in enumerate(temp_max_act):\n",
    "                max_activation[j] = max(max_activation[j], element)\n",
    "        temp_out = []  # temporary array to store outputs\n",
    "        for neuron in neuron_array:  # for every neuron\n",
    "            if net_type == \"SNN\":\n",
    "                number_of_total_spikes += neuron.n_spikes\n",
    "            if neuron.layer == (len(network_structure) - 1):  # if output neuron\n",
    "                if net_type == \"SNN\":\n",
    "                    temp_out.append(\n",
    "                        neuron.n_spikes\n",
    "                    )  # append number of spikes per output neuron\n",
    "                else:\n",
    "                    temp_out.append(neuron.output)  # append value of output neuron\n",
    "        output_array.append(temp_out)  # append to output values\n",
    "    print(\"\\r\", f\"\", end=\"\")\n",
    "    output_array = np.array(output_array)  # convert tu numpy array\n",
    "\n",
    "    return output_array, max_activation  # output values, max_activation per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `normalization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalization(max_activation):\n",
    "    weight_factor = [1, 1]\n",
    "    bias_factor = [1, 1]\n",
    "    v_th = [1, 1]\n",
    "\n",
    "    for i, value in enumerate(weight_factor):  # layer-wise adaption of weights\n",
    "        weight_factor[i] = value * max_activation[i] / max_activation[i + 1]\n",
    "    for i, value in enumerate(bias_factor):  # layer-wise adaption of biases\n",
    "        bias_factor[i] = value / max_activation[i + 1]\n",
    "\n",
    "    return weight_factor, bias_factor, v_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `scale_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the weights and biases\n",
    "def scale_model(structure, weights, biases, w_factor, b_factor, fp_convert):\n",
    "    scaled_weights = []\n",
    "    scaled_biases = []\n",
    "    factor_counter = 0\n",
    "    inlayer_counter = 0\n",
    "\n",
    "    for weight in weights:\n",
    "        if fp_convert:\n",
    "            scaled_weights.append([round(i * w_factor[factor_counter]) for i in weight])\n",
    "        else:\n",
    "            scaled_weights.append([i * w_factor[factor_counter] for i in weight])\n",
    "        inlayer_counter += 1\n",
    "        if inlayer_counter >= structure[factor_counter + 1]:\n",
    "            inlayer_counter = 0\n",
    "            factor_counter += 1\n",
    "    factor_counter = 0\n",
    "    inlayer_counter = 0\n",
    "    for bias in biases:\n",
    "        if fp_convert:\n",
    "            scaled_biases.append(round(bias * b_factor[factor_counter]))\n",
    "        else:\n",
    "            scaled_biases.append(bias * b_factor[factor_counter])\n",
    "        inlayer_counter += 1\n",
    "        if inlayer_counter >= structure[factor_counter + 1]:\n",
    "            inlayer_counter = 0\n",
    "            factor_counter += 1\n",
    "    # print(f\"Scaled Weights: {scaled_weights} Bias: {scaled_biases}\")  # debug\n",
    "\n",
    "    return scaled_weights, scaled_biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `decode_output_spikes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spike rate\n",
    "def decode_output_spikes(spikes, steps):\n",
    "    spike_ratio = (\n",
    "        np.array(spikes) / steps\n",
    "    )  # spike_ratio = number_of_spikes/number_of_steps\n",
    "\n",
    "    return spike_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_input_array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_array(length):\n",
    "    input_array = np.random.randint(0, 2, size=(length, 2))\n",
    "    return input_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = create_input_array(1_000_000)\n",
    "# input_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_structure, weights, biases, classification_threshold = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_array = create_neurons(network_structure, weights, biases, 0, 0 , \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% done"
     ]
    }
   ],
   "source": [
    "output_array, max_activation = calculate_network(\n",
    "    network_structure, neuron_array, input_array, 0, \"ANN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_factor, bias_factor, v_th = data_normalization(max_activation)\n",
    "# weight_factor, bias_factor, v_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_weights, snn_biases = scale_model(\n",
    "    network_structure, weights, biases, weight_factor, bias_factor, 0\n",
    ")\n",
    "# snn_weights, snn_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_neuron_array = create_neurons(\n",
    "    network_structure, snn_weights, snn_biases, steps, [1, 1], \"SNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SNN...\n",
      " 100% done"
     ]
    }
   ],
   "source": [
    "print(\"Calculating SNN...\")\n",
    "output_spikes, not_used = calculate_network(\n",
    "    network_structure, snn_neuron_array, input_array, steps, \"SNN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.390625, 0.      , 0.      , ..., 0.140625, 0.03125 , 0.      ],\n",
       "       [0.265625, 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.4375  , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       ...,\n",
       "       [0.265625, 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.5     , 0.      , 0.      , ..., 0.03125 , 0.      , 0.      ],\n",
       "       [0.359375, 0.      , 0.      , ..., 0.234375, 0.046875, 0.      ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_ratio = decode_output_spikes(output_spikes, steps)\n",
    "spike_ratio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
