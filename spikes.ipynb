{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring new class IF_Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate and Fire Neuron Object\n",
    "\n",
    "\n",
    "class IF_Neuron:\n",
    "    def __init__(self, layer, weights, bias, steps, v_th):\n",
    "        self.layer = layer  # Layer of Neuron\n",
    "        self.weights = weights  # Weights\n",
    "        self.bias = bias  # Bias\n",
    "\n",
    "        # IF Properties\n",
    "        self.steps = steps  # Number of steps for calculation\n",
    "        self.v = np.empty([self.steps])  # Neuron Value\n",
    "        self.v[0] = 0  # Set start Value\n",
    "        self.spikes = np.empty([self.steps])  # Output spike train\n",
    "        self.n_spikes = 0  # Number of spikes\n",
    "        self.v_th = v_th  # Threshold\n",
    "\n",
    "    def reset(self):  # Reset Neuron\n",
    "        self.v = np.empty([self.steps])\n",
    "        self.v[0] = 0\n",
    "        self.spikes = np.empty([self.steps])\n",
    "        self.n_spikes = 0\n",
    "\n",
    "    def calculate(self, neuron_input):\n",
    "        for i in range(self.steps):  # for every step\n",
    "            if i > 0:  # not first element\n",
    "                self.v[i] = self.v[i - 1]\n",
    "            for j in range(len(neuron_input)):  # for every input channel\n",
    "                if neuron_input[j][i]:  # if spike present\n",
    "                    self.v[i] = self.v[i] + self.weights[j]\n",
    "            self.v[i] = self.v[i] + self.bias\n",
    "            if self.v[i] > self.v_th:  # if above threshold\n",
    "                self.n_spikes += 1  # increase number of spikes\n",
    "                self.spikes[i] = 1  # add spike to spike trace\n",
    "                self.v[i] = self.v[i] - self.v_th  # difference reset\n",
    "                # self.Vm[i] = self.bias            # hard reset\n",
    "            else:  # add no spike to spike trace\n",
    "                self.spikes[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron model for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuron Object for ANN\n",
    "class Neuron:\n",
    "    def __init__(self, layer, weights, bias):\n",
    "        self.layer = layer  # layer\n",
    "        self.weights = weights  # weights\n",
    "        self.bias = bias  # bias\n",
    "        self.output = 0  # output\n",
    "\n",
    "    def calculate(self, inputs):  # calculation\n",
    "        relu_activation = ReLU()\n",
    "        x = np.dot(self.weights, inputs) + self.bias\n",
    "        self.output = relu_activation.calculate(x)\n",
    "\n",
    "\n",
    "# ReLU activation function\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.output = 0\n",
    "\n",
    "    def calculate(self, x):\n",
    "        self.output = np.maximum(0, x)  # relu function\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `load_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network structure, weights, biases and activation of output neurons of existing ANN\n",
    "def load_model():\n",
    "    network_structure = [2, 8, 7]  # input layer, hidden layer, output layer\n",
    "    weights = np.array(\n",
    "        [\n",
    "            [3.8722e00, -1.9211e-01],\n",
    "            [5.3290e00, 4.7047e-01],\n",
    "            [-5.1274e00, -5.1903e-03],\n",
    "            [-2.1598e-01, 3.8066e00],\n",
    "            [8.6600e-02, -8.0032e00],\n",
    "            [5.6373e00, -1.5221e-01],\n",
    "            [1.2375e00, 4.9385e-01],\n",
    "            [3.5665e00, 3.5465e-01],\n",
    "            [1.4272, -6.1945, -2.0182, 1.3436, 2.2910, 0.4987, 0.3354, -3.3586],\n",
    "            [-1.1558, -0.3980, -3.7244, -1.4081, -2.3210, -1.6481, -2.1048, -0.4278],\n",
    "            [-8.2870, -1.0868, 0.8291, 0.7862, -21.4690, -17.1373, -0.5934, -0.1413],\n",
    "            [-4.1481, -0.5656, 2.4139, -9.3905, -2.0829, -16.9980, -0.0992, -0.9269],\n",
    "            [0.5731, 1.5926, -18.0025, -0.3991, -16.3425, 0.7215, 0.3035, 1.3948],\n",
    "            [0.8768, 0.5940, -13.4116, -7.6260, 0.3059, 1.4851, 0.7284, 0.3347],\n",
    "            [-7.8029, -0.9323, 0.8822, -36.0286, 3.4898, -18.0212, -3.9245, -0.6883],\n",
    "        ],\n",
    "        dtype=object,\n",
    "    )\n",
    "    biases = np.array(\n",
    "        [\n",
    "            3.1150,\n",
    "            -1.4917,\n",
    "            2.9950,\n",
    "            2.6293,\n",
    "            -2.0631,\n",
    "            3.2291,\n",
    "            1.8875,\n",
    "            -1.5298,\n",
    "            0.7810,\n",
    "            -1.4082,\n",
    "            -1.0581,\n",
    "            1.9883,\n",
    "            -1.8215,\n",
    "            0.3030,\n",
    "            -1.5795,\n",
    "        ],\n",
    "    )\n",
    "    classification_threshold = 0.5  # output activation needed to assign to class\n",
    "\n",
    "    return network_structure, weights, biases, classification_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_neurons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neurons(structure, weights, biases, steps, v_th, net_type):\n",
    "    neuron_array = []  # array in which the neuron objects will be saved\n",
    "    neuron_number = 0  # counter to initialize/create the neuron objects\n",
    "\n",
    "    for layer in range(\n",
    "        1, len(structure)\n",
    "    ):  # for every layer (except layer 0 which is input)\n",
    "        for neuron in range(structure[layer]):  # for number of neurons in layer\n",
    "            if net_type == \"SNN\":  # create SNN neurons\n",
    "                neuron_array.append(\n",
    "                    IF_Neuron(\n",
    "                        layer,\n",
    "                        weights[neuron_number],\n",
    "                        biases[neuron_number],\n",
    "                        steps,\n",
    "                        v_th[layer - 1],\n",
    "                    )\n",
    "                )\n",
    "            else:  # create ANN neurons\n",
    "                neuron_array.append(\n",
    "                    Neuron(layer, weights[neuron_number], biases[neuron_number])\n",
    "                )\n",
    "            neuron_number += 1\n",
    "\n",
    "    return neuron_array  # array of neuron objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `reset_neurons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_neurons(neuron_array):\n",
    "    for neuron in neuron_array:\n",
    "        neuron.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_input_spike`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "steps = 5\n",
    "\n",
    "\n",
    "def create_input_spike(input_array, steps):\n",
    "    input_spike = np.zeros(steps)\n",
    "    # rr_values_array=rr_values_array.astype(int)\n",
    "    # for i, value in enumerate(rr_values_array):\n",
    "    for l in range(steps):\n",
    "        rnd = random.randrange(60, 120)\n",
    "        # print(f\"rnd:{rnd}\")\n",
    "        # print(f\"input_array:{rr_values_array}\")\n",
    "        print(f\"input_spike:{input_spike}\")\n",
    "        if rnd < input_array:\n",
    "            input_spike[l] = 1\n",
    "\n",
    "    return input_spike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_input_spikes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5\n",
    "\n",
    "\n",
    "def create_input_spikes(input_array, steps):\n",
    "    input_spikes = np.zeros(steps)\n",
    "    for i in range(len(input_array)):\n",
    "        for j in range(len(input_array[i])):\n",
    "            if j == 0:\n",
    "                pass_value1 = input_array[i][j]\n",
    "                spikes1 = create_input_spike(pass_value1, steps)\n",
    "                print(f\"spikes1:{spikes1}\")\n",
    "            if j == 1:\n",
    "                pass_value2 = input_array[i][j]\n",
    "                spikes2 = create_input_spike(pass_value2, steps)\n",
    "                print(f\"spikes2:{spikes2}\")\n",
    "    return input_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `calculate_pixel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixel(network_structure, neuron_array, input_elements, net_type):\n",
    "    max_activation = [0] * len(network_structure)\n",
    "    for layer in range(1, len(network_structure)):  # for layer\n",
    "        if layer == 1:  # if input layer\n",
    "            neuron_input_array = input_elements  # get img values as input\n",
    "        else:  # otherwise, get outputs of previous layer\n",
    "            neuron_input_array = []\n",
    "            for neuron in neuron_array:\n",
    "                if neuron.layer == layer - 1:\n",
    "                    if net_type == \"SNN\":\n",
    "                        neuron_input_array.append(neuron.spikes)  # spikes output\n",
    "                    else:\n",
    "                        neuron_input_array.append(neuron.output)\n",
    "        for neuron in neuron_array:  # get all neurons of current layer and calculate\n",
    "            if neuron.layer == layer:\n",
    "                if net_type == \"SNN\":\n",
    "                    neuron.calculate(neuron_input_array)\n",
    "                else:\n",
    "                    neuron.calculate(neuron_input_array)\n",
    "                    max_activation[layer] = max(max_activation[layer], neuron.output)\n",
    "    return max_activation  # max activation per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `calculate_network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_network(network_structure, neuron_array, input_array, steps, net_type):\n",
    "    output_array = []\n",
    "    max_activation = [0] * len(network_structure)\n",
    "    max_activation[0] = 1\n",
    "    number_of_total_spikes = 0\n",
    "\n",
    "    for i, pixel in enumerate(input_array):  # for every pixel\n",
    "        if (i + 1) / len(input_array) * 100 % 1 == 0:  # print status update\n",
    "            print(\"\\r\", f\"{int((i+1)/len(input_array)*100)}% done\", end=\"\")\n",
    "        if net_type == \"SNN\":  # if SNN\n",
    "            reset_neurons(neuron_array)  # reset neurons\n",
    "            input_spikes = create_input_spikes(pixel, steps)  # convert input to spikes\n",
    "            calculate_pixel(network_structure, neuron_array, input_spikes, net_type)\n",
    "        else:  # if ANN\n",
    "            temp_max_act = calculate_pixel(\n",
    "                network_structure, neuron_array, pixel, net_type\n",
    "            )\n",
    "            for j, element in enumerate(temp_max_act):\n",
    "                max_activation[j] = max(max_activation[j], element)\n",
    "        temp_out = []  # temporary array to store outputs\n",
    "        for neuron in neuron_array:  # for every neuron\n",
    "            if net_type == \"SNN\":\n",
    "                number_of_total_spikes += neuron.n_spikes\n",
    "            if neuron.layer == (len(network_structure) - 1):  # if output neuron\n",
    "                if net_type == \"SNN\":\n",
    "                    temp_out.append(\n",
    "                        neuron.n_spikes\n",
    "                    )  # append number of spikes per output neuron\n",
    "                else:\n",
    "                    temp_out.append(neuron.output)  # append value of output neuron\n",
    "        output_array.append(temp_out)  # append to output values\n",
    "    print(\"\\r\", f\"\", end=\"\")\n",
    "    output_array = np.array(output_array)  # convert tu numpy array\n",
    "\n",
    "    return output_array, max_activation  # output values, max_activation per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `normalization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalization(max_activation):\n",
    "    weight_factor = [1, 1]\n",
    "    bias_factor = [1, 1]\n",
    "    v_th = [1, 1]\n",
    "\n",
    "    for i, value in enumerate(weight_factor):  # layer-wise adaption of weights\n",
    "        weight_factor[i] = value * max_activation[i] / max_activation[i + 1]\n",
    "    for i, value in enumerate(bias_factor):  # layer-wise adaption of biases\n",
    "        bias_factor[i] = value / max_activation[i + 1]\n",
    "\n",
    "    return weight_factor, bias_factor, v_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create_input_array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_array(length):\n",
    "    input_array = []\n",
    "    for _ in range(length):\n",
    "        temp = [random.randint(0,1), random.randint(0,1)]\n",
    "        input_array.append(temp)\n",
    "    return input_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 1],\n",
       " [0, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [0, 0],\n",
       " [0, 0],\n",
       " [0, 1],\n",
       " [1, 1],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 1],\n",
       " [1, 1],\n",
       " [0, 0],\n",
       " [0, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [0, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [0, 1],\n",
       " [0, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [0, 0],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [1, 1],\n",
       " [1, 1],\n",
       " [0, 0],\n",
       " [0, 1],\n",
       " [0, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 0],\n",
       " [0, 1],\n",
       " [0, 0],\n",
       " [1, 0],\n",
       " [0, 0],\n",
       " [1, 1]]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array = create_input_array(60)\n",
    "input_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_structure, weights, biases, classification_threshold = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_array = create_neurons(network_structure, weights, biases, 0, 0 , \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% done"
     ]
    }
   ],
   "source": [
    "output_array, max_activation = calculate_network(\n",
    "    network_structure, neuron_array, input_array, 0, \"ANN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_factor, bias_factor, v_th = data_normalization(max_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.11278534692772717, 0.5061502950067629],\n",
       " [0.11278534692772717, 0.0570863366199092],\n",
       " [1, 1])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_factor, bias_factor, v_th"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
